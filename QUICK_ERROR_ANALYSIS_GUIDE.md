# Quick Error Analysis Guide - Concurrent Edition

## ğŸš€ TL;DR - Run All Environments Fast

**Run 1 task per environment across all 122 environments with concurrency:**

```bash
cd /Users/josemoreno/Desktop/repos/apollo-tau-bench

# Fast: 3 concurrent tests, 1 task per env (~40 minutes, ~$10)
python3 run_error_analysis_all_envs.py --run-tests \
  --num-tasks 1 \
  --test-concurrency 3 \
  --analysis-concurrency 5
```

---

## âš™ï¸ Updated Default Settings

- âœ… **1 task per environment** (down from 3)
- âœ… **3 concurrent test workers** (tests 3 envs at once)
- âœ… **5 concurrent analysis workers** (analyzes 5 envs at once)

**Speed improvement:** ~3-5x faster than sequential! ğŸš€

---

## ğŸ¯ Common Use Cases

### 1. Quick Sample (5 environments, fast)
```bash
python3 run_error_analysis_all_envs.py --run-tests \
  --envs academic_search_1 banking_services_1 retail_1 airline_1 project_management_1 \
  --test-concurrency 5
```
**Time:** ~2 minutes | **Cost:** <$1

### 2. All Environments (recommended)
```bash
python3 run_error_analysis_all_envs.py --run-tests \
  --test-concurrency 3
```
**Time:** ~40 minutes | **Cost:** ~$10  
**Processing:** 122 environments Ã— 1 task = 122 tasks  
**Parallelism:** 3 tests + 5 analyses running concurrently

### 3. Maximum Speed (higher concurrency)
```bash
python3 run_error_analysis_all_envs.py --run-tests \
  --test-concurrency 5 \
  --analysis-concurrency 10
```
**Time:** ~25 minutes | **Cost:** ~$10  
âš ï¸ **Warning:** May hit rate limits - use with caution

### 4. Conservative (lower concurrency)
```bash
python3 run_error_analysis_all_envs.py --run-tests \
  --test-concurrency 1 \
  --analysis-concurrency 1
```
**Time:** ~2 hours | **Cost:** ~$10  
**Best for:** Avoiding rate limits, debugging

---

## ğŸ“Š Performance Comparison

| Mode | Concurrency | Time | Cost | When to Use |
|------|-------------|------|------|-------------|
| Sequential | 1 | ~2 hours | ~$10 | Debugging, rate limit concerns |
| Default | 3/5 | ~40 mins | ~$10 | **Recommended** - balanced |
| Fast | 5/10 | ~25 mins | ~$10 | When you need results quickly |
| Quick Sample | 5 envs | ~2 mins | <$1 | Testing, validation |

---

## ğŸ›ï¸ All Options

```bash
python3 run_error_analysis_all_envs.py \
  --run-tests \                        # Run tests if no results exist
  --num-tasks 1 \                      # Tasks per environment (default: 1)
  --test-concurrency 3 \               # Concurrent test workers (default: 3)
  --analysis-concurrency 5 \           # Concurrent analysis workers (default: 5)
  --envs env1 env2 env3 \              # Specific envs (default: all)
  --skip-analysis                      # Just run tests, no analysis
```

---

## ğŸ“ˆ Expected Timeline (All 122 Environments)

**With default settings (3 test workers, 5 analysis workers):**

```
0:00 - Start
0:20 - ~60 environments tested (3 at a time)
0:40 - All 122 environments tested
0:50 - ~100 environments analyzed (5 at a time)
0:55 - All 122 environments analyzed
âœ… Complete!
```

**Output:**
- 122 results files in `tau/results/`
- 122 analysis files in `tau/error_analyses/`
- 1 comprehensive report

---

## ğŸ’¡ Tips for Concurrent Execution

### âœ… Do:
- Use default settings (3/5) for most cases
- Monitor API usage on OpenAI dashboard
- Let it run in background with `nohup` for all envs
- Check logs if any environment fails

### âŒ Don't:
- Set concurrency too high (>10) - rate limits!
- Run multiple scripts at once - conflicts!
- Interrupt during analysis - may corrupt files

---

## ğŸ› Troubleshooting

### "Rate limit exceeded"
**Solution:** Lower concurrency:
```bash
--test-concurrency 1 --analysis-concurrency 2
```

### Output looks jumbled
**Cause:** Multiple threads printing concurrently  
**Solution:** This is normal! Check the final summary for results.

### Some environments failed
**Solution:** Check individual error messages, re-run failed ones:
```bash
python3 run_error_analysis_all_envs.py --run-tests --envs failed_env_1 failed_env_2
```

---

## ğŸ“Š Sample Output (Concurrent)

```
ğŸ” Auto Error Identification - All Environments
================================================================================

Found 122 environments

Using 3 concurrent workers

[1/122] academic_search_1
[2/122] academic_search_2
[3/122] academic_search_3
  Running 1 task(s) for academic_search_1...
  Running 1 task(s) for academic_search_2...
  Running 1 task(s) for academic_search_3...
[4/122] academic_search_4
  âœ… Analysis complete
  âœ… Analysis complete
  âœ… Analysis complete
[5/122] academic_search_5
...

================================================================================
ğŸ“Š SUMMARY
================================================================================

Total environments:        122
Tests run:                 122
Analyses completed:        118
Skipped (no results):      0
Failed:                    4

Environments with failures:
  â€¢ environment_1: 2 failures
  â€¢ environment_2: 1 failures
  ...
```

---

## ğŸ¯ Recommended Workflow

### Step 1: Quick Test (5 minutes)
Test a sample to verify everything works:
```bash
python3 run_error_analysis_all_envs.py --run-tests \
  --envs academic_search_1 banking_services_1 retail_1 \
  --test-concurrency 3
```

### Step 2: Full Run (40 minutes)
Run all environments:
```bash
python3 run_error_analysis_all_envs.py --run-tests \
  --test-concurrency 3 \
  --analysis-concurrency 5
```

### Step 3: Review Results
```bash
cd tau/error_analyses
cat comprehensive_report.json | python3 -m json.tool
```

### Step 4: Fix Issues
Based on findings, fix environment bugs or agent issues.

### Step 5: Re-run Failed Environments
```bash
python3 run_error_analysis_all_envs.py --run-tests \
  --envs failed_env_1 failed_env_2
```

---

## âœ… What Changed

### Before (Sequential)
- 1 environment at a time
- 3 tasks per environment
- ~3-4 hours for all
- Simple but slow

### After (Concurrent)
- **1 task per environment** (faster tests)
- **3 environments tested concurrently** (3x speed)
- **5 environments analyzed concurrently** (5x speed)
- **~40 minutes for all** (5x faster overall)
- Thread-safe logging

---

## ğŸš€ Ready to Run!

**Default command (recommended):**
```bash
python3 run_error_analysis_all_envs.py --run-tests
```

This will:
- âœ… Run 1 task per environment
- âœ… Test 3 environments concurrently
- âœ… Analyze 5 environments concurrently
- âœ… Complete all 122 environments in ~40 minutes
- âœ… Cost ~$10 in API calls

**Let it run and check back in 40 minutes!** â˜•

